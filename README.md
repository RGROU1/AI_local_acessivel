# IA Local Acessível (Zero Custo de API) – Ollama + Open WebUI

Stack **100% local**, simples e acessível, para rodar **IA generativa** sem custo de API e **sem necessidade de conexão**.  

Ideal para situações em que não há disponibilidade de rede, que exigem **privacidade, segurança** ou **poucos recursos financeiros** — incluindo rodar **LLaMA 3.2 (3B)** em CPU comum.

## Por que este projeto?

- **Acessibilidade**: tenha uma IA **local** que funciona mesmo **sem internet**, acessível para diversos usos (estudos, marketing, negócios, prototipagem).  
- **Privacidade**: tudo roda local, nenhum dado enviado para nuvem.  
- **Zero custo de API**: só é preciso baixar o modelo uma vez; depois, o uso é ilimitado.  
- **Simplicidade**: um comando (`docker compose up -d`) e você já tem um “ChatGPT local” pronto.  
- **Flexibilidade**: escolha o modelo de IA mais adequado (leve, rápido ou profundo).  

---

## Como rodar

1. Clone o repositório:
   ```bash
   git clone https://github.com/SEU_USUARIO/meu-ai-stack.git
   cd meu-ai-stack
